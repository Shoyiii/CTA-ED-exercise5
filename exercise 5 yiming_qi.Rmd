---
title: "exercise 5"
author: "Yiming Qi"
date: "2024-03-12"
output: html_document
---

#Q1
```{r}
#set up
library(tidyverse)
library(stringr)
library(tidytext) 
library(topicmodels) 
library(gutenbergr)
library(scales)
library(tm)
library(ggthemes)
library(readr)
library(quanteda)
library(quanteda.textmodels)
devtools::install_github("matthewjdenny/preText")
library(preText)
```

```{r}
#download and combine Mary Wollstonecraft's "A Vindication of the Rights of Woman" (ID 134) and "Maria; Or, The Wrongs of Woman" (ID 3420) into a single dataset, including author's information
tocq <- gutenberg_download(c(134, 3420), 
                            meta_fields = "author")
```

```{r}
#assign booknumber, preprocess text, and create document-term matrix
tocq_words <- tocq %>%
  mutate(booknumber = ifelse(gutenberg_id==134, "DiA1", "DiA2")) %>%
  unnest_tokens(word, text) %>%
  filter(!is.na(word)) %>%
  count(booknumber, word, sort = TRUE) %>%
  ungroup() %>%
  anti_join(stop_words)

tocq_dtm <- tocq_words %>%
  cast_dtm(booknumber, word, n)

tm::inspect(tocq_dtm)
```

```{r}
#perform LDA on document-term matrix with 15 topics and set seed for reproducibility
tocq_lda <- LDA(tocq_dtm, k = 15, control = list(seed = 1234))
```

```{r}
#extract the per-topic-per-word probabilities, called "β" from the model
tocq_topics <- tidy(tocq_lda, matrix = "beta")
head(tocq_topics, n = 10)
```

```{r}
#plots the top terms, in terms of beta
tocq_top_terms <- tocq_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

tocq_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 4) +
  scale_y_reordered() +
  theme_tufte(base_family = "Helvetica")
```

```{r}
#plot relative word frequencies
tidy_tocq <- tocq %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_tocq %>%
  count(word, sort = TRUE)

bookfreq <- tidy_tocq %>%
  mutate(booknumber = ifelse(gutenberg_id==134, "DiA1", "DiA2")) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(booknumber, word) %>%
  group_by(booknumber) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(booknumber, proportion)

ggplot(bookfreq, aes(x = DiA1, y = DiA2, color = abs(DiA1 - DiA2))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  theme_tufte(base_family = "Helvetica") +
  theme(legend.position="none", 
        strip.background = element_blank(), 
        strip.text.x = element_blank()) +
  labs(x = "Wollstonecraft DiA 2", y = "Wollstonecraft DiA 1") +
  coord_equal()

```
Graph analysis:

Based on these observations, we can begin to infer that the LDA model may have successfully captured the core themes and differences in Mary Wollstonecraft's two works.

In "A Vindication of the Rights of Woman" (DiA1), the high frequency of words such as “modesty,” “knowledge,” “duties,” “virtue,” “rational,” “beauty,” and “affection” indicates that this work emphasizes the role and qualities of women in society, as well as discussions on women's moral and rational capacities. These concepts are related to the public sphere, moral philosophy, and female education.

Conversely, in "Maria; or, The Wrongs of Woman" (DiA2), words like “left,” “returned,” “discovered,” “bound,” “husband,” and “child” appearing with high frequency may reflect a more personal level of narrative, such as domestic life, personal relationships, and the challenges and experiences of women in the private sphere.

```{r}
#split into chapter documents
tocq <- tocq %>%
  filter(!is.na(text))

tocq_chapter <- tocq %>%
  mutate(booknumber = ifelse(gutenberg_id==134, "DiA1", "DiA2")) %>%
  group_by(booknumber) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, booknumber, chapter)

#split into words
tocq_chapter_word <- tocq_chapter %>%
  unnest_tokens(word, text)

#find document-word counts
tocq_word_counts <- tocq_chapter_word %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE) %>%
  ungroup()
tocq_word_counts

#cast into DTM format for LDA analysis
tocq_chapters_dtm <- tocq_word_counts %>%
  cast_dtm(document, word, n)

tm::inspect(tocq_chapters_dtm)
```

```{r}
#re-estimate the topic model with this new DocumentTermMatrix object, specifying k equal to 2
tocq_chapters_lda <- LDA(tocq_chapters_dtm, k = 2, control = list(seed = 1234))
```

```{r}
#extract document-topic distributions from LDA model for chapters analysis
tocq_chapters_gamma <- tidy(tocq_chapters_lda, matrix = "gamma")
tocq_chapters_gamma
```

```{r}
#split document into title and chapter, identify dominant topics, and filter for inconsistencies in topic assignments
tocq_chapters_gamma <- tocq_chapters_gamma %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)

tocq_chapter_classifications <- tocq_chapters_gamma %>%
  group_by(title, chapter) %>%
  top_n(1, gamma) %>%
  ungroup()

tocq_book_topics <- tocq_chapter_classifications %>%
  count(title, topic) %>%
  group_by(title) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = title, topic)

tocq_chapter_classifications %>%
  inner_join(tocq_book_topics, by = "topic") %>%
  filter(title != consensus)

#look document-word pairs were to see which words in each documents were assigned
assignments <- augment(tocq_chapters_lda, data = tocq_chapters_dtm)
assignments

assignments <- assignments %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
  inner_join(tocq_book_topics, by = c(".topic" = "topic"))

assignments %>%
  count(title, consensus, wt = count) %>%
  group_by(title) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(consensus, title, fill = percent)) +
  geom_tile() +
  scale_fill_gradient2(high = "red", label = percent_format()) +
  geom_text(aes(x = consensus, y = title, label = scales::percent(percent))) +
  theme_tufte(base_family = "Helvetica") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.grid = element_blank()) +
  labs(x = "Book words assigned to",
       y = "Book words came from",
       fill = "% of assignments")
```
Graph analysis:

The model seems to perform slightly better at correctly assigning words from DiA2 (69.6%) than DiA1 (63.1%). However, there is a substantial amount of misclassification as well, with 30.4% of words from DiA2 being incorrectly assigned to DiA1, and 36.9% of words from DiA1 being incorrectly assigned to DiA2.


#Q2 

```{r}
#load in corpus of  text data.
corp <- corpus(tocq, text_field = "text")
#use first 10 documents for example
documents <- corp[sample(1:10000,10)]
#take a look at the document names
print(names(documents[1:10]))
```

```{r}
preprocessed_documents <- factorial_preprocessing(
    documents,
    use_ngrams = TRUE,
    infrequent_term_threshold = 0.2,
    verbose = FALSE)
```

```{r, eval = F}
preText_results <- preText(
    preprocessed_documents,
    dataset_name = "Wollstonecraft text",
    distance_method = "cosine",
    num_comparisons = 20,
    verbose = FALSE)
```

```{r}
preText_score_plot(preText_results)
```
